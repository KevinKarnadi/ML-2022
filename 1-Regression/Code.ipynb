{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Te27fi-0pP"
      },
      "source": [
        "# **Regression**\n",
        "\n",
        "1.  Basic Part: Implement a regression model to predict the number of dengue cases\n",
        "\n",
        "> *   Step 1: Split Data\n",
        "> *   Step 2: Preprocess Data\n",
        "> *   Step 3: Implement Regression\n",
        "> *   Step 4: Make Prediction\n",
        "> *   Step 5: Train Model and Generate Result\n",
        "\n",
        "2.  Advanced Part: Implement a regression model to predict the number of dengue cases in a different way than the basic part"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDdnos-4uUv"
      },
      "source": [
        "# 1. Basic Part\n",
        "\n",
        "Implement a regression model to predict the number of dengue cases"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCR7vk9BFkf"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HL5XjqFf4wSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWjrzi0dMPz"
      },
      "source": [
        "## Global attributes\n",
        "\n",
        "Define the global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EWLDPOlHBbcK"
      },
      "outputs": [],
      "source": [
        "input_dataroot = 'basic_input.csv'\n",
        "output_dataroot = 'basic.csv'\n",
        "\n",
        "input_datalist =  [] # Initial datalist, saved as numpy array\n",
        "output_datalist =  [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n",
        "# The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OUbS2BEgcut6"
      },
      "outputs": [],
      "source": [
        "# Global variables\n",
        "x = []\n",
        "y = []\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_validation = []\n",
        "y_validation = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "w_basic = []\n",
        "degree = 2\n",
        "y_terms = 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoRFoQjBW5S"
      },
      "source": [
        "## Load the Input File\n",
        "\n",
        "First, load the basic input file **basic_input.csv**\n",
        "\n",
        "Input data would be stored in *input_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dekR1KnqBtI6"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(input_dataroot, newline='') as csvfile:\n",
        "  input_datalist = np.array(list(csv.reader(csvfile)))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6kYPuikLCFx4"
      },
      "source": [
        "## Implement the Regression Model\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jWwdx06JNEYs"
      },
      "source": [
        "### Step 1: Split Data\n",
        "\n",
        "Split data in *input_datalist* into training dataset and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "USDciENcB-5F"
      },
      "outputs": [],
      "source": [
        "def SplitData():\n",
        "  global x, y, x_train, x_test, y_train, y_test\n",
        "\n",
        "  # Split input & output\n",
        "  x = input_datalist[1:105, 1:4]\n",
        "  y = input_datalist[1:105, 4:7]\n",
        "\n",
        "  # Split training data & testing data\n",
        "  x_train = x[:94]\n",
        "  y_train = y[:94]\n",
        "  x_test = x[94:]\n",
        "  y_test = y[94:]\n",
        "\n",
        "  return"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u-3Qln4aNgVy"
      },
      "source": [
        "### Step 2: Preprocess Data\n",
        "\n",
        "Handle the unreasonable data\n",
        "\n",
        "Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XXvW1n_5NkQ5"
      },
      "outputs": [],
      "source": [
        "def PreprocessData():\n",
        "  global x_train, y_train, x_validation, y_validation\n",
        "\n",
        "  # Filter missing values\n",
        "  temp_x = []\n",
        "  for idx in range(0, 3):\n",
        "    temp_x.append([float(x) for x in x_train[:, idx] if x])\n",
        "  temp_y = []\n",
        "  for idx in range(0, 3):\n",
        "    temp_y.append([float(y) for y in y_train[:, idx] if y])\n",
        "\n",
        "  # Quartiles and IQR\n",
        "  q25_x = []\n",
        "  for idx in range(0, 3):\n",
        "    q25_x.append(np.percentile(temp_x[idx][:], 25))\n",
        "  q75_x = []\n",
        "  for idx in range(0, 3):\n",
        "    q75_x.append(np.percentile(temp_x[idx][:], 75))\n",
        "  iqr_x = []\n",
        "  for idx in range(0, 3):\n",
        "    iqr_x.append(q75_x[idx] - q25_x[idx])\n",
        "  q25_y = []\n",
        "  for idx in range(0, 3):\n",
        "    q25_y.append(np.percentile(temp_y[idx][:], 25))\n",
        "  q75_y = []\n",
        "  for idx in range(0, 3):\n",
        "    q75_y.append(np.percentile(temp_y[idx][:], 75))\n",
        "  iqr_y = []\n",
        "  for idx in range(0, 3):\n",
        "    iqr_y.append(q75_y[idx] - q25_y[idx])\n",
        "\n",
        "  #  Filter outliers\n",
        "  for idx in range(0, 3):\n",
        "    temp_x[idx] = [x for x in temp_x[idx] if not(x < q25_x[idx] - 1.5*iqr_x[idx] or x > q75_x[idx] + 1.5*iqr_x[idx])]\n",
        "  for idx in range(0, 3):\n",
        "    temp_y[idx] = [y for y in temp_y[idx] if not(y < q25_y[idx] - 1.5*iqr_y[idx] or y > q75_y[idx] + 1.5*iqr_y[idx])]\n",
        "\n",
        "  # Mean values\n",
        "  mean_x = []\n",
        "  for idx in range(0, 3):\n",
        "    mean_x.append(np.mean(temp_x[idx]))\n",
        "  mean_y = []\n",
        "  for idx in range(0, 3):\n",
        "    mean_y.append(np.mean(temp_y[idx]))\n",
        "\n",
        "  # Standard deviations\n",
        "  sd_x = []\n",
        "  for idx in range(0, 3):\n",
        "    sd_x.append(np.std(temp_x[idx]))\n",
        "  sd_y = []\n",
        "  for idx in range(0, 3):\n",
        "    sd_y.append(np.std(temp_y[idx]))\n",
        "\n",
        "  # Deal with missing values\n",
        "\n",
        "  for x in x_train:\n",
        "    for idx in range(0, 3):\n",
        "      if x[idx] == '':\n",
        "        x[idx] = mean_x[idx]\n",
        "  for y in y_train:\n",
        "    for idx in range(0, 3):\n",
        "      if y[idx] == '':\n",
        "        y[idx] = mean_y[idx]\n",
        "\n",
        "  # Deal with outliers\n",
        "  \n",
        "  # Interquartile range method\n",
        "  for x in x_train:\n",
        "    for idx in range(0, 3):\n",
        "      if float(x[idx]) < q25_x[idx] - 1.5*iqr_x[idx] or float(x[idx]) > q75_x[idx] + 1.5*iqr_x[idx]:\n",
        "        #print(x[idx]+\" is an outlier.\")\n",
        "        x[idx] = mean_x[idx]\n",
        "  for y in y_train:\n",
        "    for idx in range(0, 3):\n",
        "      if float(y[idx]) < q25_y[idx] - 1.5*iqr_y[idx] or float(y[idx]) > q75_y[idx] + 1.5*iqr_y[idx]:\n",
        "        #print(y[idx]+\" is an outlier.\")\n",
        "        y[idx] = mean_y[idx]\n",
        "  \n",
        "  len = 84\n",
        "  x_validation = x_train[len:]\n",
        "  y_validation = y_train[len:]\n",
        "  x_train = x_train[:len]\n",
        "  y_train = y_train[:len]\n",
        "\n",
        "  return"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLpJmQUN3V6"
      },
      "source": [
        "### Step 3: Implement Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Tx9n1_23N8C0"
      },
      "outputs": [],
      "source": [
        "def MSE(y_predicted, y_true, idx):\n",
        "\n",
        "  squared_error = (y_predicted[:, idx] - y_true[:, idx].astype(float)) ** 2\n",
        "  sum_squared_error = np.sum(squared_error)\n",
        "  mse = sum_squared_error / len(y_true[:, idx])\n",
        "\n",
        "  return mse\n",
        "\n",
        "def MAPE(y_predicted, y_true, idx):\n",
        "\n",
        "  mape = np.mean(np.abs((y_true[:, idx].astype(float) - y_predicted[:, idx]) / y_true[:, idx].astype(float)))\n",
        "\n",
        "  return \"{:.2%}\".format(mape)\n",
        "\n",
        "def Regression():\n",
        "  global x_train, y_train, x_validation, y_validation, w_basic, degree, y_terms\n",
        "\n",
        "  mean_y = []\n",
        "  for i in range(0, 3):\n",
        "    mean_y.append(np.mean(y_train[:, i].astype(float)))\n",
        "\n",
        "  xA = np.ones(len(x_train[:, 0])).reshape((len(x_train[:, 0]), 1))\n",
        "  for p in range(1, degree+1):\n",
        "    xA = np.insert(xA, p, (x_train[:, 0].astype(float))**p, axis = 1)\n",
        "  for i in range(1, y_terms+1):\n",
        "    arr = y_train[:len(y_train[:, 0])-i, 0].astype(float)\n",
        "    for j in range(0, i):\n",
        "      arr = np.insert(arr, 0, mean_y[0])\n",
        "    xA = np.insert(xA, degree+i, arr, axis = 1)\n",
        "  yA = y_train[:, 0].reshape((len(y_train[:, 0]), 1)).astype(float)\n",
        "  w_basic.append(np.dot(np.dot(np.linalg.inv(np.dot(xA.transpose(), xA)), xA.transpose()), yA))\n",
        "\n",
        "  xB = np.ones(len(x_train[:, 1])).reshape((len(x_train[:, 1]), 1))\n",
        "  for p in range(1, degree+1):\n",
        "    xB = np.insert(xB, p, (x_train[:, 1].astype(float))**p, axis = 1)\n",
        "  for i in range(1, y_terms+1):\n",
        "    arr = y_train[:len(y_train[:, 1])-i, 1].astype(float)\n",
        "    for j in range(0, i):\n",
        "      arr = np.insert(arr, 0, mean_y[1])\n",
        "    xB = np.insert(xB, degree+i, arr, axis = 1)\n",
        "  yB = y_train[:, 1].reshape((len(y_train[:, 1]), 1)).astype(float)\n",
        "  w_basic.append(np.dot(np.dot(np.linalg.inv(np.dot(xB.transpose(), xB)), xB.transpose()), yB))\n",
        "\n",
        "  xC = np.ones(len(x_train[:, 2])).reshape((len(x_train[:, 2]), 1))\n",
        "  for p in range(1, degree+1):\n",
        "    xC = np.insert(xC, p, (x_train[:, 2].astype(float))**p, axis = 1)\n",
        "  for i in range(1, y_terms+1):\n",
        "    arr = y_train[:len(y_train[:, 2])-i, 2].astype(float)\n",
        "    for j in range(0, i):\n",
        "      arr = np.insert(arr, 0, mean_y[2])\n",
        "    xC = np.insert(xC, degree+i, arr, axis = 1)\n",
        "  yC = y_train[:, 2].reshape((len(y_train[:, 2]), 1)).astype(float)\n",
        "  w_basic.append(np.dot(np.dot(np.linalg.inv(np.dot(xC.transpose(), xC)), xC.transpose()), yC))\n",
        "\n",
        "  y_predicted_train = []\n",
        "  idx = 0\n",
        "  for x in x_train:\n",
        "    l = []\n",
        "    for i in range(0, 3):\n",
        "      sum = 0\n",
        "      for p in range(0, degree+1):\n",
        "        sum += w_basic[i][p] * float(x[i]) ** p\n",
        "      y = mean_y[i]\n",
        "      if idx > 0:\n",
        "        y = y_train[idx-1, i]\n",
        "      sum += w_basic[i][degree+1] * float(y)\n",
        "      y2 = mean_y[i]\n",
        "      if idx > 1:\n",
        "        y2 = y_train[idx-2, i]\n",
        "      sum += w_basic[i][degree+2] * float(y2)\n",
        "      y3 = mean_y[i]\n",
        "      if idx > 2:\n",
        "        y3 = y_train[idx-3, i]\n",
        "      sum += w_basic[i][degree+3] * float(y3)\n",
        "      l.append(float(sum))\n",
        "    idx += 1\n",
        "    y_predicted_train.append(l)\n",
        "  y_predicted_train = np.array(y_predicted_train)\n",
        "  \n",
        "  y_predicted_validation = []\n",
        "  idx = 0\n",
        "  for x in x_validation:\n",
        "    l = []\n",
        "    for i in range(0, 3):\n",
        "      sum = 0\n",
        "      for p in range(0, degree+1):\n",
        "        sum += w_basic[i][p] * float(x[i]) ** p\n",
        "      y = y_train[len(y_train)-1, i]\n",
        "      if idx > 0:\n",
        "        y = y_validation[idx-1, i]\n",
        "      sum += w_basic[i][degree+1] * float(y)\n",
        "      y2 = 0\n",
        "      if idx < 2:\n",
        "        y2 = y_train[len(y_train)+(idx-2), i]\n",
        "      elif idx >= 2:\n",
        "        y2 = y_validation[idx-2, i]\n",
        "      sum += w_basic[i][degree+2] * float(y2)\n",
        "      y3 = 0\n",
        "      if idx < 3:\n",
        "        y3 = y_train[len(y_train)+(idx-3), i]\n",
        "      elif idx >= 3:\n",
        "        y3 = y_validation[idx-3, i]\n",
        "      sum += w_basic[i][degree+3] * float(y3)\n",
        "      l.append(float(sum))\n",
        "    idx += 1\n",
        "    y_predicted_validation.append(l)\n",
        "  y_predicted_validation = np.array(y_predicted_validation)\n",
        "\n",
        "  '''\n",
        "  print(\"MSE of Training Data A:\", MSE(y_predicted_train, y_train, 0))\n",
        "  print(\"MSE of Training Data B:\", MSE(y_predicted_train, y_train, 1))\n",
        "  print(\"MSE of Training Data C:\", MSE(y_predicted_train, y_train, 2))\n",
        "  print()\n",
        "  print(\"MSE of Validation Data A:\", MSE(y_predicted_validation, y_validation, 0))\n",
        "  print(\"MSE of Validation Data B:\", MSE(y_predicted_validation, y_validation, 1))\n",
        "  print(\"MSE of Validation Data C:\", MSE(y_predicted_validation, y_validation, 2))\n",
        "  print()\n",
        "  '''\n",
        "\n",
        "  '''\n",
        "  print(\"MAPE of Training Data A:\", MAPE(y_predicted_train, y_train, 0))\n",
        "  print(\"MAPE of Training Data B:\", MAPE(y_predicted_train, y_train, 1))\n",
        "  print(\"MAPE of Training Data C:\", MAPE(y_predicted_train, y_train, 2))\n",
        "  print()\n",
        "  print(\"MAPE of Validation Data A:\", MAPE(y_predicted_validation, y_validation, 0))\n",
        "  print(\"MAPE of Validation Data B:\", MAPE(y_predicted_validation, y_validation, 1))\n",
        "  print(\"MAPE of Validation Data C:\", MAPE(y_predicted_validation, y_validation, 2))\n",
        "  print()\n",
        "  '''\n",
        "\n",
        "  return"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRNFwyN8xd"
      },
      "source": [
        "### Step 4: Make Prediction\n",
        "\n",
        "Make prediction of testing dataset and store the value in *output_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EKlDIC2-N_lk"
      },
      "outputs": [],
      "source": [
        "def MakePrediction():\n",
        "  global output_datalist, x_test, y_test, y_validation, w_basic, degree\n",
        "\n",
        "  week = 202143\n",
        "  idx = 0\n",
        "  for x in x_test:\n",
        "    l = []\n",
        "    l.append(week)\n",
        "    for i in range(0, 3):\n",
        "      sum = 0\n",
        "      for p in range(0, degree+1):\n",
        "        sum += w_basic[i][p] * float(x[i]) ** p\n",
        "      y = y_validation[len(y_validation)-1, i]\n",
        "      if idx > 0:\n",
        "        y = y_test[idx-1, i]\n",
        "      sum += w_basic[i][degree+1] * float(y)\n",
        "      y2 = 0\n",
        "      if idx < 2:\n",
        "        y2 = y_validation[len(y_validation)+(idx-2), i]\n",
        "      elif idx >= 2:\n",
        "        y2 = y_test[idx-2, i]\n",
        "      sum += w_basic[i][degree+2] * float(y2)\n",
        "      y3 = 0\n",
        "      if idx < 3:\n",
        "        y3 = y_validation[len(y_validation)+(idx-3), i]\n",
        "      elif idx >= 3:\n",
        "        y3 = y_test[idx-3, i]\n",
        "      sum += w_basic[i][degree+3] * float(y3)\n",
        "      l.append(float(sum))\n",
        "      y_test[idx, i] = float(sum)\n",
        "    idx += 1\n",
        "    week += 1\n",
        "    output_datalist.append(l)\n",
        "\n",
        "  return"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cCd0Z6izOCwq"
      },
      "source": [
        "### Step 5: Train Model and Generate Result\n",
        "\n",
        "* If the regression model is *3x^2 + 2x^1 + 1*, your output would be: \n",
        "```\n",
        "3 2 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCL92EPKOFIn",
        "outputId": "97decbf4-f5f4-4750-d4a9-a605df7171c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Format: w0 + w1*x + w2*x^2 + w3*y[i-1] + w4*y[i-2] + w5*y[i-3]\n",
            "88.19744587259379 -6.123390631560916 0.11384392120334641 0.5532560607501292 0.14248971985171283 0.16509213933900213 \n",
            "-286.69249426099907 25.388943141300537 -0.5517987983452397 0.45913991116650466 0.28395048599523554 0.10977712288018998 \n",
            "5.041109722450386 -0.1923212523452138 0.0025648023383381124 0.6810187202913461 0.17893169141710188 0.08744350879374774 \n"
          ]
        }
      ],
      "source": [
        "SplitData()\n",
        "PreprocessData()\n",
        "Regression()\n",
        "MakePrediction()\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Format: w0 + w1*x + w2*x^2 + w3*y[i-1] + w4*y[i-2] + w5*y[i-3]\")\n",
        "for w in w_basic:\n",
        "  for i in w:\n",
        "    print(i[0], end = \" \")\n",
        "  print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Jhd8wAOk3D"
      },
      "source": [
        "## Write the Output File\n",
        "\n",
        "Write the prediction to output csv\n",
        "> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tYQVYLlKOtDB"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4408qg4xMQ"
      },
      "source": [
        "# 2. Advanced Part\n",
        "\n",
        "Implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaZCe19m41g1",
        "outputId": "07e06ade-b1d7-4dc6-b89f-4286b2363356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Format: w0 + w1*x1 + w2*x1^2 + w3*x2 + w4*x2^2 + w5*y[i-1] + w6*y[i-2] + w7*y[i-3]\n",
            "82.75884027372678 -5.728073098360248 0.10580930531350285 0.20983511711331437 -0.009150342848267198 0.5552548485326276 0.1365937751060622 0.1679260197946708 \n",
            "-303.741287542661 26.871644969015243 -0.5828241984013879 0.23009084744854147 -0.04270006824116442 0.44622737088028147 0.2813561028026016 0.1206999373560042 \n",
            "Format: w0 + w1*x1 + w2*x1^2 + w3*x2 + w4*x2^2 + w5*y[i-1] + w6*y[i-2]\n",
            "-21.889704078344295 2.0123402971008773 -0.03955183400834408 -0.3371501236324219 0.00897571588491172 0.717896225997679 0.23653063625403709 \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "input_dataroot1 = 'basic_input.csv'\n",
        "input_dataroot2 = 'advanced_input1.csv'\n",
        "input_dataroot3 = 'advanced_input2.csv'\n",
        "output_dataroot2 = 'advanced.csv'\n",
        "\n",
        "input_datalist2_1 =  []\n",
        "input_datalist2_2 =  []\n",
        "input_datalist2_3 =  []\n",
        "output_datalist2 =  []\n",
        "\n",
        "# Global variables\n",
        "x2 = []\n",
        "y2 = []\n",
        "x_train2 = []\n",
        "y_train = []\n",
        "x_validation2 = []\n",
        "y_validation2 = []\n",
        "x_test2 = []\n",
        "y_test2 = []\n",
        "w_advanced = []\n",
        "degree2 = 2\n",
        "y_terms2 = 3\n",
        "y_terms2c = 2\n",
        "\n",
        "\n",
        "with open(input_dataroot1, newline='') as csvfile:\n",
        "  input_datalist2_1 = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "with open(input_dataroot2, newline='') as csvfile:\n",
        "  input_datalist2_2 = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "with open(input_dataroot3, newline='') as csvfile:\n",
        "  input_datalist2_3 = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "\n",
        "def SplitData2():\n",
        "  global x2, y2, x_train2, x_test2, y_train2, y_test2\n",
        "\n",
        "  # Split input & output\n",
        "  x2 = np.concatenate((input_datalist2_1[1:105, 1:4], input_datalist2_2[1:105, 1:4]), axis = 1)\n",
        "  y2 = input_datalist2_1[1:105, 4:7]\n",
        "\n",
        "  # Split training data & testing data\n",
        "  x_train2 = x2[:94]\n",
        "  y_train2 = y2[:94]\n",
        "  x_test2 = x2[94:]\n",
        "  y_test2 = y2[94:]\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def PreprocessData2():\n",
        "  global x_train2, y_train2, x_validation2, y_validation2\n",
        "\n",
        "  # Filter missing values\n",
        "  temp_x = []\n",
        "  for idx in range(0, 6):\n",
        "    temp_x.append([float(x) for x in x_train2[:, idx] if x])\n",
        "  temp_y = []\n",
        "  for idx in range(0, 3):\n",
        "    temp_y.append([float(y) for y in y_train2[:, idx] if y])\n",
        "\n",
        "  # Quartiles and IQR\n",
        "  q25_x = []\n",
        "  for idx in range(0, 6):\n",
        "    q25_x.append(np.percentile(temp_x[idx][:], 25))\n",
        "  q75_x = []\n",
        "  for idx in range(0, 6):\n",
        "    q75_x.append(np.percentile(temp_x[idx][:], 75))\n",
        "  iqr_x = []\n",
        "  for idx in range(0, 6):\n",
        "    iqr_x.append(q75_x[idx] - q25_x[idx])\n",
        "  q25_y = []\n",
        "  for idx in range(0, 3):\n",
        "    q25_y.append(np.percentile(temp_y[idx][:], 25))\n",
        "  q75_y = []\n",
        "  for idx in range(0, 3):\n",
        "    q75_y.append(np.percentile(temp_y[idx][:], 75))\n",
        "  iqr_y = []\n",
        "  for idx in range(0, 3):\n",
        "    iqr_y.append(q75_y[idx] - q25_y[idx])\n",
        "\n",
        "  #  Filter outliers\n",
        "  for idx in range(0, 6):\n",
        "    temp_x[idx] = [x for x in temp_x[idx] if not(x < q25_x[idx] - 1.5*iqr_x[idx] or x > q75_x[idx] + 1.5*iqr_x[idx])]\n",
        "  for idx in range(0, 3):\n",
        "    temp_y[idx] = [y for y in temp_y[idx] if not(y < q25_y[idx] - 1.5*iqr_y[idx] or y > q75_y[idx] + 1.5*iqr_y[idx])]\n",
        "\n",
        "  # Mean values\n",
        "  mean_x = []\n",
        "  for idx in range(0, 6):\n",
        "    mean_x.append(np.mean(temp_x[idx]))\n",
        "  mean_y = []\n",
        "  for idx in range(0, 3):\n",
        "    mean_y.append(np.mean(temp_y[idx]))\n",
        "\n",
        "  # Standard deviations\n",
        "  sd_x = []\n",
        "  for idx in range(0, 6):\n",
        "    sd_x.append(np.std(temp_x[idx]))\n",
        "  sd_y = []\n",
        "  for idx in range(0, 3):\n",
        "    sd_y.append(np.std(temp_y[idx]))\n",
        "\n",
        "  # Deal with missing values\n",
        "\n",
        "  for x in x_train2:\n",
        "    for idx in range(0, 6):\n",
        "      if x[idx] == '':\n",
        "        x[idx] = mean_x[idx]\n",
        "  for y in y_train2:\n",
        "    for idx in range(0, 3):\n",
        "      if y[idx] == '':\n",
        "        y[idx] = mean_y[idx]\n",
        "\n",
        "  # Deal with outliers\n",
        "  \n",
        "  # Interquartile range method\n",
        "  for x in x_train2:\n",
        "    for idx in range(0, 6):\n",
        "      if float(x[idx]) < q25_x[idx] - 1.5*iqr_x[idx] or float(x[idx]) > q75_x[idx] + 1.5*iqr_x[idx]:\n",
        "        #print(x[idx]+\" is an outlier.\")\n",
        "        x[idx] = mean_x[idx]\n",
        "  for y in y_train2:\n",
        "    for idx in range(0, 3):\n",
        "      if float(y[idx]) < q25_y[idx] - 1.5*iqr_y[idx] or float(y[idx]) > q75_y[idx] + 1.5*iqr_y[idx]:\n",
        "        #print(y[idx]+\" is an outlier.\")\n",
        "        y[idx] = mean_y[idx]\n",
        "  \n",
        "  len = 84\n",
        "  x_validation2 = x_train2[len:]\n",
        "  y_validation2 = y_train2[len:]\n",
        "  x_train2 = x_train2[:len]\n",
        "  y_train2 = y_train2[:len]\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def MSE2(y_predicted, y_true, idx):\n",
        "\n",
        "  squared_error = (y_predicted[:, idx] - y_true[:, idx].astype(float)) ** 2\n",
        "  sum_squared_error = np.sum(squared_error)\n",
        "  mse = sum_squared_error / len(y_true[:, idx])\n",
        "\n",
        "  return mse\n",
        "\n",
        "def MAPE2(y_predicted, y_true, idx):\n",
        "\n",
        "  mape = np.mean(np.abs((y_true[:, idx].astype(float) - y_predicted[:, idx]) / y_true[:, idx].astype(float)))\n",
        "\n",
        "  return \"{:.2%}\".format(mape)\n",
        "\n",
        "def Regression2():\n",
        "  global x_train2, y_train2, x_validation2, y_validation2, w_advanced, degree2, y_terms2, y_terms2c\n",
        "\n",
        "  mean_y = []\n",
        "  for i in range(0, 3):\n",
        "    mean_y.append(np.mean(y_train2[:, i].astype(float)))\n",
        "\n",
        "  xA = np.ones(len(x_train2[:, 0])).reshape((len(x_train2[:, 0]), 1))\n",
        "  for p in range(1, degree2+1):\n",
        "    xA = np.insert(xA, p, (x_train2[:, 0].astype(float))**p, axis = 1)\n",
        "  for p in range(1, degree2+1):\n",
        "    xA = np.insert(xA, degree2+p, (x_train2[:, 3].astype(float))**p, axis = 1)\n",
        "  for i in range(1, y_terms2+1):\n",
        "    arr = y_train2[:len(y_train2[:, 0])-i, 0].astype(float)\n",
        "    for j in range(0, i):\n",
        "      arr = np.insert(arr, 0, mean_y[0])\n",
        "    xA = np.insert(xA, 2*degree2+i, arr, axis = 1)\n",
        "  yA = y_train2[:, 0].reshape((len(y_train2[:, 0]), 1)).astype(float)\n",
        "  w_advanced.append(np.dot(np.dot(np.linalg.inv(np.dot(xA.transpose(), xA)), xA.transpose()), yA))\n",
        "\n",
        "  xB = np.ones(len(x_train2[:, 1])).reshape((len(x_train2[:, 1]), 1))\n",
        "  for p in range(1, degree2+1):\n",
        "    xB = np.insert(xB, p, (x_train2[:, 1].astype(float))**p, axis = 1)\n",
        "  for p in range(1, degree2+1):\n",
        "    xB = np.insert(xB, degree2+p, (x_train2[:, 4].astype(float))**p, axis = 1)\n",
        "  for i in range(1, y_terms2+1):\n",
        "    arr = y_train2[:len(y_train2[:, 1])-i, 1].astype(float)\n",
        "    for j in range(0, i):\n",
        "      arr = np.insert(arr, 0, mean_y[1])\n",
        "    xB = np.insert(xB, 2*degree2+i, arr, axis = 1)\n",
        "  yB = y_train2[:, 1].reshape((len(y_train2[:, 1]), 1)).astype(float)\n",
        "  w_advanced.append(np.dot(np.dot(np.linalg.inv(np.dot(xB.transpose(), xB)), xB.transpose()), yB))\n",
        "\n",
        "  xC = np.ones(len(x_train2[:, 2])).reshape((len(x_train2[:, 2]), 1))\n",
        "  for p in range(1, degree2+1):\n",
        "    xC = np.insert(xC, p, (x_train2[:, 2].astype(float))**p, axis = 1)\n",
        "  for p in range(1, degree2+1):\n",
        "    xC = np.insert(xC, degree2+p, (x_train2[:, 5].astype(float))**p, axis = 1)\n",
        "  for i in range(1, y_terms2c+1):\n",
        "    arr = y_train2[:len(y_train2[:, 2])-i, 2].astype(float)\n",
        "    for j in range(0, i):\n",
        "      arr = np.insert(arr, 0, mean_y[2])\n",
        "    xC = np.insert(xC, 2*degree2+i, arr, axis = 1)\n",
        "  yC = y_train2[:, 2].reshape((len(y_train2[:, 2]), 1)).astype(float)\n",
        "  w_advanced.append(np.dot(np.dot(np.linalg.inv(np.dot(xC.transpose(), xC)), xC.transpose()), yC))\n",
        "\n",
        "  y_predicted_train = []\n",
        "  idx = 0\n",
        "  for x in x_train2:\n",
        "    l = []\n",
        "    for i in range(0, 3):\n",
        "      sum = 0\n",
        "      for p in range(0, degree2+1):\n",
        "        sum += w_advanced[i][p] * float(x[i]) ** p\n",
        "      for p in range(1, degree2+1):\n",
        "        sum += w_advanced[i][degree2+p] * float(x[i+3]) ** p\n",
        "      y = mean_y[i]\n",
        "      if idx > 0:\n",
        "        y = y_train2[idx-1, i]\n",
        "      sum += w_advanced[i][2*degree2+1] * float(y)\n",
        "      y2 = mean_y[i]\n",
        "      if idx > 1:\n",
        "        y2 = y_train2[idx-2, i]\n",
        "      sum += w_advanced[i][2*degree2+2] * float(y2)\n",
        "      if i != 2:\n",
        "        y3 = mean_y[i]\n",
        "        if idx > 2:\n",
        "          y3 = y_train2[idx-3, i]\n",
        "        sum += w_advanced[i][2*degree2+3] * float(y3)\n",
        "      l.append(float(sum))\n",
        "    idx += 1\n",
        "    y_predicted_train.append(l)\n",
        "  y_predicted_train = np.array(y_predicted_train)\n",
        "  \n",
        "  y_predicted_validation = []\n",
        "  idx = 0\n",
        "  for x in x_validation2:\n",
        "    l = []\n",
        "    for i in range(0, 3):\n",
        "      sum = 0\n",
        "      for p in range(0, degree2+1):\n",
        "        sum += w_advanced[i][p] * float(x[i]) ** p\n",
        "      for p in range(1, degree2+1):\n",
        "        sum += w_advanced[i][degree2+p] * float(x[i+3]) ** p\n",
        "      y = y_train2[len(y_train2)-1, i]\n",
        "      if idx > 0:\n",
        "        y = y_validation2[idx-1, i]\n",
        "      sum += w_advanced[i][2*degree2+1] * float(y)\n",
        "      y2 = 0\n",
        "      if idx < 2:\n",
        "        y2 = y_train2[len(y_train2)+(idx-2), i]\n",
        "      elif idx >= 2:\n",
        "        y2 = y_validation2[idx-2, i]\n",
        "      sum += w_advanced[i][2*degree2+2] * float(y2)\n",
        "      if i != 2:\n",
        "        y3 = 0\n",
        "        if idx < 3:\n",
        "          y3 = y_train2[len(y_train2)+(idx-3), i]\n",
        "        elif idx >= 3:\n",
        "          y3 = y_validation2[idx-3, i]\n",
        "        sum += w_advanced[i][2*degree2+3] * float(y3)\n",
        "      l.append(float(sum))\n",
        "    idx += 1\n",
        "    y_predicted_validation.append(l)\n",
        "  y_predicted_validation = np.array(y_predicted_validation)\n",
        "\n",
        "  '''\n",
        "  print(\"MSE of Training Data A:\", MSE2(y_predicted_train, y_train2, 0))\n",
        "  print(\"MSE of Training Data B:\", MSE2(y_predicted_train, y_train2, 1))\n",
        "  print(\"MSE of Training Data C:\", MSE2(y_predicted_train, y_train2, 2))\n",
        "  print()\n",
        "  print(\"MSE of Validation Data A:\", MSE2(y_predicted_validation, y_validation2, 0))\n",
        "  print(\"MSE of Validation Data B:\", MSE2(y_predicted_validation, y_validation2, 1))\n",
        "  print(\"MSE of Validation Data C:\", MSE2(y_predicted_validation, y_validation2, 2))\n",
        "  print()\n",
        "  '''\n",
        "\n",
        "  '''\n",
        "  print(\"MAPE of Training Data A:\", MAPE2(y_predicted_train, y_train2, 0))\n",
        "  print(\"MAPE of Training Data B:\", MAPE2(y_predicted_train, y_train2, 1))\n",
        "  print(\"MAPE of Training Data C:\", MAPE2(y_predicted_train, y_train2, 2))\n",
        "  print()\n",
        "  print(\"MAPE of Validation Data A:\", MAPE2(y_predicted_validation, y_validation2, 0))\n",
        "  print(\"MAPE of Validation Data B:\", MAPE2(y_predicted_validation, y_validation2, 1))\n",
        "  print(\"MAPE of Validation Data C:\", MAPE2(y_predicted_validation, y_validation2, 2))\n",
        "  print()\n",
        "  '''\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def MakePrediction2():\n",
        "  global output_datalist2, x_test2, y_test2, y_validation2, w_advanced, degree2\n",
        "\n",
        "  week = 202143\n",
        "  idx = 0\n",
        "  for x in x_test2:\n",
        "    l = []\n",
        "    l.append(week)\n",
        "    for i in range(0, 3):\n",
        "      sum = 0\n",
        "      for p in range(0, degree2+1):\n",
        "        sum += w_advanced[i][p] * float(x[i]) ** p\n",
        "      for p in range(1, degree2+1):\n",
        "        sum += w_advanced[i][degree2+p] * float(x[i+3]) ** p\n",
        "      y = y_validation2[len(y_validation2)-1, i]\n",
        "      if idx > 0:\n",
        "        y = y_test2[idx-1, i]\n",
        "      sum += w_advanced[i][2*degree2+1] * float(y)\n",
        "      y2 = 0\n",
        "      if idx < 2:\n",
        "        y2 = y_validation2[len(y_validation2)+(idx-2), i]\n",
        "      elif idx >= 2:\n",
        "        y2 = y_test2[idx-2, i]\n",
        "      sum += w_advanced[i][2*degree2+2] * float(y2)\n",
        "      if i != 2:\n",
        "        y3 = 0\n",
        "        if idx < 3:\n",
        "          y3 = y_validation2[len(y_validation2)+(idx-3), i]\n",
        "        elif idx >= 3:\n",
        "          y3 = y_test2[idx-3, i]\n",
        "        sum += w_advanced[i][2*degree2+3] * float(y3)\n",
        "      l.append(float(sum))\n",
        "      y_test2[idx, i] = float(sum)\n",
        "    idx += 1\n",
        "    week += 1\n",
        "    output_datalist2.append(l)\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "SplitData2()\n",
        "PreprocessData2()\n",
        "Regression2()\n",
        "MakePrediction2()\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Format: w0 + w1*x1 + w2*x1^2 + w3*x2 + w4*x2^2 + w5*y[i-1] + w6*y[i-2] + w7*y[i-3]\")\n",
        "idx = 0\n",
        "for w in w_advanced:\n",
        "  if idx == 2:\n",
        "    print(\"Format: w0 + w1*x1 + w2*x1^2 + w3*x2 + w4*x2^2 + w5*y[i-1] + w6*y[i-2]\")\n",
        "  for i in w:\n",
        "    print(i[0], end = \" \")\n",
        "  print()\n",
        "  idx += 1\n",
        "\n",
        "\n",
        "with open(output_dataroot2, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist2:\n",
        "    writer.writerow(row)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
