{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IagZMs0_qjdL"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "In this project, we will build a deep neural network step by step. In this notebook, we will implement all the functions required to build a neural network from scratch. We will then train the deep neural network, consisting of three steps: forward propagation, backward propagation and parameter update."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yGFR00CQvoaH"
      },
      "source": [
        "# 2. Packages\n",
        "*   numpy : the fundamental package for scientific computing with Python.\n",
        "*   matplotlib : a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
        "*   math : Python has a built-in module that we can use for mathematical tasks.\n",
        "*   sklearn.datasets : scikit-learn comes with a few small standard datasets that do not require to download any file from some external website. We will be using the breast cancer wisconsin dataset to build a binary classifier.\n",
        "\n",
        "âš ï¸ **NOTICE** âš ï¸: \n",
        "*   np.random.seed(1) is used to keep all the random function calls consistent.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fmTH9UkeqdYf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn import datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w35ZkTwMc00G"
      },
      "source": [
        "# 3. Neural network\n",
        "In this section, we will implement a deep neural network from scratch.\n",
        "\n",
        "As mentioned before, the process of training a deep neural network is composed of three steps: forward propagation, backward propagation, and parameter update."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x0KHo8w9yqbY"
      },
      "outputs": [],
      "source": [
        "class Dense():\n",
        "    \n",
        "    def __init__(self, n_x, n_y, seed=1):\n",
        "        self.n_x = n_x\n",
        "        self.n_y = n_y\n",
        "        self.seed = seed\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        \"\"\"\n",
        "        Argument:\n",
        "        self.n_x -- size of the input layer\n",
        "        self.n_y -- size of the output layer\n",
        "        self.parameters -- python dictionary containing your parameters:\n",
        "                           W -- weight matrix of shape (n_y, n_x)\n",
        "                           b -- bias vector of shape (n_y, 1)\n",
        "        \"\"\"\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "        limit = math.sqrt(6 / (self.n_x + self.n_y))\n",
        "        W = np.random.uniform(-limit, limit, (self.n_y, self.n_x))\n",
        "        b = np.zeros((self.n_y, 1))\n",
        "\n",
        "        assert(W.shape == (self.n_y, self.n_x))\n",
        "        assert(b.shape == (self.n_y, 1))\n",
        "\n",
        "        self.parameters = {\"W\": W, \"b\": b}\n",
        "\n",
        "    def forward(self, A):\n",
        "        \"\"\"\n",
        "        Implement the linear part of a layer's forward propagation.\n",
        "\n",
        "        Arguments:\n",
        "        A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
        "        self.cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
        "\n",
        "        Returns:\n",
        "        Z -- the input of the activation function, also called pre-activation parameter \n",
        "        \"\"\"\n",
        "\n",
        "        Z = np.dot(self.parameters[\"W\"], A) + self.parameters[\"b\"]\n",
        "        self.cache = (A, self.parameters[\"W\"], self.parameters[\"b\"])\n",
        "        \n",
        "        assert(Z.shape == (self.parameters[\"W\"].shape[0], A.shape[1]))\n",
        "        \n",
        "        return Z\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "        Arguments:\n",
        "        dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "        self.cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "        self.dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "        self.db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "\n",
        "        Returns:\n",
        "        dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "\n",
        "        \"\"\"\n",
        "        A_prev, W, b = self.cache\n",
        "        m = A_prev.shape[1]\n",
        "\n",
        "        self.dW = 1/m * np.dot(dZ, A_prev.T)\n",
        "        self.db = 1/m * np.sum(dZ, axis = 1, keepdims = True)\n",
        "        dA_prev = np.dot(W.T, dZ)\n",
        "        \n",
        "        assert (dA_prev.shape == A_prev.shape)\n",
        "        assert (self.dW.shape == self.parameters[\"W\"].shape)\n",
        "        assert (self.db.shape == self.parameters[\"b\"].shape)\n",
        "        \n",
        "        return dA_prev\n",
        "\n",
        "    def update(self, learning_rate):\n",
        "        \"\"\"\n",
        "        Update parameters using gradient descent\n",
        "        \n",
        "        Arguments:\n",
        "        learning rate -- step size\n",
        "        \"\"\"\n",
        "\n",
        "        self.parameters[\"W\"] = self.parameters[\"W\"] - learning_rate * self.dW\n",
        "        self.parameters[\"b\"] = self.parameters[\"b\"] - learning_rate * self.db"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P_krGKUNg_Ix"
      },
      "source": [
        "## 3.1 Implement a linear layer\n",
        "First, we will start by implementing one of the most commonly used layers in the deep neural network, called the dense layer. The dense layer is a linear layer applying a linear transformation to the incoming data:\n",
        "$Z = WA + b$, where $W$ and $b$ are the weight and bias.\n",
        "\n",
        "**Note**: Dense layers, also known as Fully-connected layers, connect every input neuron to every output neuron and are commonly used in neural networks."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1.1. Initialize parameters\n",
        "We will create and initialize parameters of a linear layer using Glorot uniform initialization.\n",
        "\n",
        "**Instructions**:\n",
        "*   Use random initialization (uniform distribution) for the weight matrices. Draws samples from a uniform distribution within [-limit, limit], where limit = sqrt(6 / (fan_in + fan_out)) (fan_in is the number of input units in the weight tensor and fan_out is the number of output units).\n",
        "*   Use zero initialization for the biases."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "abu7YqxeAeMz"
      },
      "source": [
        "### 3.1.2. Linear forward\n",
        "\n",
        "After initializing parameters, we will need to apply the linear transformation to the incoming data, and this can be simply done by matrix multiplication and addition.\n",
        "\n",
        "We will implement linear forward by applying the linear transformation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-K8_obj6vIeT"
      },
      "source": [
        "### 3.1.3. Linear backward\n",
        "Backpropagation is used to calculate the gradient of the loss function with respect to the parameters.\n",
        "\n",
        "For layer $l$, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).\n",
        "\n",
        "Suppose we have already calculated the derivative $dZ^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial Z^{[l]}}$. We want to get $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$.\n",
        "\n",
        "The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$ are computed using the input $dZ^{[l]}$.Here are the formulas we need:$$ dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} $$$$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)} $$$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} $$\n",
        "\n",
        "We will use the 3 formulas above to implement `linear_backward()`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XWNWxxutN47B"
      },
      "source": [
        "### 3.1.4. Linear update parameters\n",
        "In this section we will update the parameters of the linear layer, using gradient descent:\n",
        "\n",
        "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} $$$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} $$\n",
        "\n",
        "We will implement update() to update our parameters using gradient descent.\n",
        "\n",
        "**Instructions**: \n",
        "*   Update parameters using gradient descent on $W^{[l]}$ and $b^{[l]}$.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "syt1bV3bdI_f"
      },
      "source": [
        "## 3.2. Activation function layer\n",
        "\n",
        "In this section, we will need to implement activation function layers. There are many activation functions, such as sigmoid function, softmax function, ReLU function and etc. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nnuv8MmebMgg"
      },
      "outputs": [],
      "source": [
        "from logging import fatal\n",
        "class Activation():\n",
        "\n",
        "    def __init__(self, function):\n",
        "        self.function = function\n",
        "\n",
        "    def forward(self, Z):\n",
        "        if self.function == \"sigmoid\":\n",
        "            \"\"\"\n",
        "            Implements the sigmoid activation in numpy\n",
        "            \n",
        "            Arguments:\n",
        "            Z -- numpy array of any shape\n",
        "            self.cache -- stores Z as well, useful during backpropagation\n",
        "            \n",
        "            Returns:\n",
        "            A -- output of sigmoid(z), same shape as Z\n",
        "            \n",
        "            \"\"\"\n",
        "\n",
        "            A = []\n",
        "            for i in Z:\n",
        "                l = []\n",
        "                for n in i:\n",
        "                    if n >= 0:\n",
        "                        l.append(1 / (1 + math.exp(-1 * n)))\n",
        "                    else:\n",
        "                        l.append(math.exp(n) / (1 + math.exp(n)))\n",
        "                A.append(l)\n",
        "            A = np.array(A)\n",
        "            self.cache = Z\n",
        "            \n",
        "            return A\n",
        "\n",
        "        elif self.function == \"softmax\":\n",
        "            \"\"\"\n",
        "            Implements the softmax activation in numpy\n",
        "            \n",
        "            Arguments:\n",
        "            Z -- numpy array of any shape (dim 0: number of classes, dim 1: number of samples)\n",
        "            self.cache -- stores Z as well, useful during backpropagation\n",
        "            \n",
        "            Returns:\n",
        "            A -- output of softmax(z), same shape as Z\n",
        "            \"\"\"\n",
        "\n",
        "            self.cache = Z\n",
        "            Z = Z.T\n",
        "            E = math.e\n",
        "            A = []\n",
        "            for i in Z:\n",
        "                b = max(i)\n",
        "                exp_values = [E**(n-b) for n in i]\n",
        "                l = exp_values / sum(exp_values)\n",
        "                A.append(l)\n",
        "            A = np.array(A)\n",
        "            A = A.T\n",
        "            \n",
        "            return A\n",
        "\n",
        "        elif self.function == \"relu\":\n",
        "            \"\"\"\n",
        "            Implement the RELU function in numpy\n",
        "            Arguments:\n",
        "            Z -- numpy array of any shape\n",
        "            self.cache -- stores Z as well, useful during backpropagation\n",
        "            Returns:\n",
        "            A -- output of relu(z), same shape as Z\n",
        "            \n",
        "            \"\"\"\n",
        "            A = np.array([[max(n, 0) for n in i] for i in Z])\n",
        "            self.cache = Z\n",
        "            \n",
        "            assert(A.shape == Z.shape)\n",
        "            \n",
        "            return A\n",
        "\n",
        "    def backward(self, dA=None, Y=None):\n",
        "        if self.function == \"sigmoid\":\n",
        "            \"\"\"\n",
        "            Implement the backward propagation for a single SIGMOID unit.\n",
        "            Arguments:\n",
        "            dA -- post-activation gradient, of any shape\n",
        "            self.cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "            Returns:\n",
        "            dZ -- Gradient of the cost with respect to Z\n",
        "            \"\"\"\n",
        "            \n",
        "            Z = self.cache\n",
        "            output = self.forward(Z)\n",
        "            derivative = output * (1-output)\n",
        "            dZ = dA * derivative\n",
        "            \n",
        "            assert (dZ.shape == Z.shape)\n",
        "            \n",
        "            return dZ\n",
        "\n",
        "        elif self.function == \"relu\":\n",
        "            \"\"\"\n",
        "            Implement the backward propagation for a single RELU unit.\n",
        "            Arguments:\n",
        "            dA -- post-activation gradient, of any shape\n",
        "            self.cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "            Returns:\n",
        "            dZ -- Gradient of the cost with respect to Z\n",
        "            \"\"\"\n",
        "            \n",
        "            Z = self.cache\n",
        "            dZ = np.array(dA, copy = True) # just converting dz to a correct object. \n",
        "            dZ[Z <= 0] = 0 # When z <= 0, we should set dz to 0 as well.\n",
        "            \n",
        "            assert (dZ.shape == Z.shape)\n",
        "            \n",
        "            return dZ\n",
        "\n",
        "        elif self.function == \"softmax\":\n",
        "            \"\"\"\n",
        "            Implement the backward propagation for a [SOFTMAX->CCE LOSS] unit.\n",
        "            Arguments:\n",
        "            Y -- true \"label\" vector (one hot vector, for example: [[1], [0], [0]] represents rock, [[0], [1], [0]] represents paper, [[0], [0], [1]] represents scissors \n",
        "                                      in a Rock-Paper-Scissors image classification), shape (number of classes, number of examples)\n",
        "            self.cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "            Returns:\n",
        "            dZ -- Gradient of the cost with respect to Z\n",
        "            \"\"\"\n",
        "            \n",
        "            Z = self.cache\n",
        "            s = self.forward(Z)\n",
        "            dZ = s - Y\n",
        "            \n",
        "            assert (dZ.shape == Z.shape)\n",
        "            \n",
        "            return dZ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5PkLKaFWiWmF"
      },
      "source": [
        "### 3.2.1. Activation forward\n",
        "#### 3.2.1.1. Sigmoid function\n",
        "Sigmoid: $\\sigma(Z) = \\begin{cases}\n",
        "    \\frac{1}{1+e^{-Z}},& \\text{if } Z >= 0\\\\\n",
        "    \\frac{e^{Z}}{1+e^{Z}}, & \\text{otherwise}\n",
        "\\end{cases}$. \n",
        "\n",
        "â—**Important**â—: As we can see, there is an exponential function inside the sigmoid function, so we might encounter an exponential overflow problem when implementing this function. To solve this problem, we use the numerically stable sigmoid function as shown in the equation above.\n",
        "\n",
        "#### 3.2.1.2. Softmax function\n",
        "Softmax: $\\sigma(\\vec{Z})_i = \\frac{e^{Z_i-b}}{\\sum_{j=1}^{K} e^{Z_j-b}}$, where $\\vec{Z}$ = input vector, $K$ = number of classes in the multi-class classifier, $b$ is $\\max_{j=1}^{K} Z_j$\n",
        "\n",
        "â—**Important**â—: The naive implementation $\\sigma(\\vec{Z})_i = \\frac{e^{Z_i}}{\\sum_{j=1}^{K} e^{Z_j}}$ is terrible when there are large numbers! We might encounter the following problems if we use the naive implementation.\n",
        "*   RuntimeWarning: overflow encountered in exp\n",
        "\n",
        "\n",
        "#### 3.2.1.3. ReLU (rectified linear unit) function\n",
        "ReLU: $RELU(Z) = max(Z, 0)$\n",
        "\n",
        "**Instruction**: \n",
        "*   Sigmoid: This function returns one item and stores one item: the activation value \"a\" and a cache contains \"z\" (it's what we will use in to the corresponding backward function).\n",
        "*   Softmax: This function returns one item and stores one item: the activation value \"a\" and a cache contains \"z\" (it's what we will use in to the corresponding backward function).\n",
        "*   ReLU: This function returns one item and stores one item: the activation value \"a\" and a cache contains \"z\" (it's what we will use in to the corresponding backward function)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0tlaPl8PpcbE"
      },
      "source": [
        "### 3.2.2. Activation backward\n",
        "Next, we will need to implement the backward functions of `sigmoid()`, `relu()` and `softmax()`+`compute_CCE_cost`.\n",
        "\n",
        "**Instruction**:\n",
        "*   sigmoid_backward: Implements the backward propagation for SIGMOID unit.\n",
        "*   relu_backward: Implements the backward propagation for RELU unit.\n",
        "*   softmax_CCE_backward: Implements the backward propagation for [SOFTMAX->CCE_LOSS] unit.\n",
        "\n",
        "If $g(.)$ is the activation function, sigmoid_backward, relu_backward and softmax_backward compute$$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})$$\n",
        "\n",
        "1. The derivative of the sigmoid function is: $$Ïƒ^{'}(Z^{[l]}) = Ïƒ(Z^{[l]}) (1 - Ïƒ(Z^{[l]}))$$. <br>\n",
        "â—**Important**â—: We should use the numerically stable sigmoid function to prevent the overflow exponential problem. \n",
        "\n",
        "2. The derivative of the relu function is: $$g'(Z^{[l]}) = \\begin{cases}\n",
        "    1,& \\text{if } Z^{[l]}> 0\\\\\n",
        "    0,              & \\text{otherwise}\n",
        "\\end{cases}$$\n",
        "\n",
        "3. TLDRðŸ˜‰: The derivative of the categorical cross-entropy loss with respect to the last hidden layer is: $$\\frac{\\partial \\mathcal{L}}{\\partial Z} = s - y $$. <br> The derivative of the softmax function is: $$\\frac{\\partial S(z_i)}{\\partial z_j} = \\begin{cases}\n",
        "    S(z_i) \\times (1 - S(z_i)),& \\text{if } i = j\\\\\n",
        "    -S(z_i) \\times S(z_j),              & \\text{if } i \\neq j\n",
        "\\end{cases}$$, where $z$ is a vector with shape (number of classes K, 1) and $S(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$. Hence, the real derivative of softmax function would be a full Jacobian matrix. For the special case, K = 4, we have <img src=\"https://miro.medium.com/max/554/1*SWfgFQLDIPXDf1C6CHmr8A.png\" height=\"100\"/>. <br> It is quite complicated to calculate the softmax derivative on its own. However, if we use the softmax and the cross entropy loss, that complexity fades away. Since the softmax layer is usually used at the output, we can actually calculate the derivative of the categorical cross-entropy loss with respect to the n-th node in the last hidden layer. Instead of a long clunky formula, we end up with this terse, easy to compute thing: $$\\frac{\\partial \\mathcal{L}}{\\partial Z_i} = s_i - y_i $$, where $s$ is the output of the softmax function and the $y$ is the true label vector(one-hot vector). For more information, we can refer to this article [Derivative of the Softmax Function and the Categorical Cross-Entropy Loss](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1). <br> \n",
        "â—**Important**â—: The above mathematical derivation is based on naive implementation. In order to deal with the exponential overflow problem, we should use the normalized exponential function when counting $s$. For the sake of simplicity, we just use the same gradient equation as the naive implementation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RYqpQu6Eye7h"
      },
      "source": [
        "## 3.3. Model\n",
        "Now, we have all the tools that are needed to build a model. Let's get started!\n",
        "\n",
        "### 3.3.1. Model initialize parameters\n",
        "First, we will need to initialize our model by creating several linear and activation function layers. \n",
        "\n",
        "**Instruction**:\n",
        "*   Use the functions we have previously written.\n",
        "*   Store all the linear layers in a list called linear.\n",
        "*   Store all the activation function layers in a list called activation.\n",
        "\n",
        "â—**Important**â—: We set the random seed for grading purposes to keep all the random function calls consistent. However, we still want all the linear layers to have different initialized weights, so when implementing this function, please make sure that we pass the number of iterations as the seed number to the Dense layer initialization call.\n",
        "\n",
        "**Note**: In deep learning, a linear-activation layer is counted as a single layer in the neural network, not two layers since the activation layer does not have any parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0JGMzfIDCSVz"
      },
      "outputs": [],
      "source": [
        "class Model():\n",
        "    \n",
        "    def __init__(self, units, activation_functions):\n",
        "        self.units = units\n",
        "        self.activation_functions = activation_functions\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        self.units -- number of nodes/units for each layer, starting from the input dimension and ending with the output dimension (i.e., [4, 4, 1])\n",
        "        self.activation_functions -- activation functions used in each layer (i.e, [\"relu\", \"sigmoid\"])\n",
        "        self.linear -- a list to store the dense layers when initializing the model\n",
        "        self.activation -- a list to store the activation function layers when initializing the model\n",
        "        \"\"\"\n",
        "        self.linear = []\n",
        "        self.activation = []\n",
        "\n",
        "        for i in range(len(self.units) - 1):\n",
        "            self.linear.append(Dense(self.units[i], self.units[i+1], seed = i))\n",
        "            activation_function = self.activation_functions[i]\n",
        "            self.activation.append(Activation(activation_function))\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        X -- input data: (number of features, number of examples)\n",
        "        \n",
        "        Returns:\n",
        "        A -- output of L-layer neural network, probability vector corresponding to your label predictions, shape (number of classes, number of examples)\n",
        "        \"\"\"\n",
        "        A = X\n",
        "\n",
        "        for i in range(len(self.units) - 1):\n",
        "            Z = self.linear[i].forward(A)\n",
        "            A = self.activation[i].forward(Z)\n",
        "\n",
        "        return A\n",
        "\n",
        "    def backward(self, AL=None, Y=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        For multi-class classification,\n",
        "        AL -- output of L-layer neural network, probability vector corresponding to your label predictions, shape (number of classes, number of examples)\n",
        "        Y -- true \"label\" vector (one hot vector, for example: [[1], [0], [0]] represents rock, [[0], [1], [0]] represents paper, [[0], [0], [1]] represents scissors \n",
        "                              in a Rock-Paper-Scissors image classification), shape (number of classes, number of examples)\n",
        "\n",
        "        Returns:\n",
        "        dA_prev -- post-activation gradient\n",
        "        \"\"\"\n",
        "\n",
        "        L = len(self.linear)\n",
        "\n",
        "        if self.activation_functions[-1] == \"sigmoid\":\n",
        "            # Initializing the backpropagation\n",
        "            E = 1e-5\n",
        "            dAL = - (np.divide(Y, AL + E) - np.divide(1 - Y, 1 - AL + E)) # derivative of cost with respect to AL, where E = 1e-5 is added to prevent zero division.\n",
        "            \n",
        "            # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL\". Outputs: \"dA_prev\"\n",
        "            dZ = self.activation[-1].backward(dAL)\n",
        "            dA_prev = self.linear[-1].backward(dZ)\n",
        "        else:\n",
        "            # Initializing the backpropagation\n",
        "            dZ = self.activation[-1].backward(AL, Y)\n",
        "\n",
        "            # Lth layer (LINEAR) gradients. Inputs: \"dZ\". Outputs: \"dA_prev\"\n",
        "            dA_prev = self.linear[-1].backward(dZ)\n",
        "\n",
        "        # Loop from l=L-2 to l=0\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        # Inputs: \"dA_prev\". Outputs: \"dA_prev\"\n",
        "        for i in range(L-2, -1, -1):\n",
        "            dZ = self.activation[i].backward(dA_prev)\n",
        "            dA_prev = self.linear[i].backward(dZ)\n",
        "\n",
        "        return dA_prev\n",
        "\n",
        "    def update(self, learning_rate):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        learning_rate -- step size\n",
        "        \"\"\"\n",
        "\n",
        "        L = len(self.linear)\n",
        "\n",
        "        for i in range(L):\n",
        "            l = self.linear[i]\n",
        "            l.parameters[\"W\"] = l.parameters[\"W\"] - learning_rate * l.dW\n",
        "            l.parameters[\"b\"] = l.parameters[\"b\"] - learning_rate * l.db"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pJVlZeyNAu-y"
      },
      "source": [
        "### 3.3.2. Model forward\n",
        "\n",
        "After that, we will implement the model forward function by calling the forward function of each layer in the linear and activation function layer we have created in the previous step.\n",
        "\n",
        "For a $N$-layer neural network, we will call the forward function of the linear layers and then followed by the activation function layers for $N-1$ times. The last activation function layer will be sigmoid for binary classification and softmax for multi-class classification.\n",
        "\n",
        "**Instruction**:\n",
        "*   Use the functions we have previously written.\n",
        "*   Use a for loop to replicate [LINEAR->ACTIVATION] (N-1) times.\n",
        "\n",
        "**Note**: There are K nodes in the last layer for K-class classification, but only one node for binary classification. Intuitively, this could be pretty confusing sometimes since there should be two nodes in the last layer for binary classification. However, both the one-node(sigmoid, binary cross-entropy) and two-node(softmax, categorical cross-entropy) techniques for binary classification work fine, and picking one technique over the other is a matter of subjective preference. We will implement the former one, which is what we usually do for binary classification.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hPBl7iq7N2wY"
      },
      "source": [
        "### 3.3.3. Model backward\n",
        "Now we will implement the backward function for the whole network. Recall that we have implemented the backward function for the dense and activation function layer. In this section, we will call these functions to help us implement the model backward function. We will iterate through all the hidden layers backward, starting from layer $L$. On each step, we will call the backward function of layer $l$ to backpropagate through layer $l$.\n",
        "\n",
        "**Instruction**:\n",
        "*   Use the functions we have previously written.\n",
        "*   Initialize backpropagation.\n",
        "*   Use a for loop to backprop from layer $L-1$ to layer $1$.\n",
        "\n",
        "Initializing backpropagation:\n",
        "\n",
        "(1) Binary classification: To backpropagate through this network, we know that the output is, $A^{[L]} = \\sigma(Z^{[L]})$. Our code thus needs to compute dAL $= \\frac{\\partial \\mathcal{L}}{\\partial A^{[L]}}$. To do so, use this formula (derived using calculus which we don't need in-depth knowledge of):\n",
        "```\n",
        "dAL = - (np.divide(Y, AL + Ïµ) - np.divide(1 - Y, 1 - AL + Ïµ)) # derivative of cost with respect to AL, where Ïµ = 1e-5 is added to prevent zero division.\n",
        "```\n",
        "\n",
        "We can then use this post-activation gradient dAL to keep going backward. We can now feed in dAL into the LINEAR->SIGMOID backward function we implemented (which will use the cached values stored inside each layer in the forward pass). After that, we will have to use a for loop to iterate through all the other layers using the LINEAR->RELU backward function. \n",
        "\n",
        "(2) Multi-class classification: Since we have implemented the backward function of the softmax activation function layer along with the categorical cross-entropy loss, we can directly call the softmax_CCE_backward function implemented inside the activation function layer and followed by the linear backward function to obtain the post-activation gradient to keep going backward. After that, we will have to use a for loop to iterate through all the other layers using the LINEAR->RELU backward function.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5wiJu3YlUCc7"
      },
      "source": [
        "### 3.3.4. Model update parameters\n",
        "In this section we will update the parameters of the model, using gradient descent:\n",
        "\n",
        "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} $$$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} $$\n",
        "where $\\alpha$ is the learning rate.\n",
        "\n",
        "**Instructions**: \n",
        "*   Use the functions we have previously written.\n",
        "*   Update parameters using gradient descent on every $W^{[l]}$ and $b^{[l]}$ for $l = 1, 2, ..., L$.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SmSBVaQOSRrk"
      },
      "source": [
        "# 4. Cost function\n",
        "In this section, we will implement the cost function. We use binary cross-entropy loss for binary classification and categorical cross-entropy loss for multi-class classification. We need to compute the cost, because we want to check if our model is actually learning. Cross-entropy loss is minimized, where smaller values represent a better model than larger values. A model that predicts perfect probabilities has a cross entropy or log loss of 0.0.\n",
        "\n",
        "## 4.1. Binary cross-entropy loss\n",
        "Compute the binary cross-entropy cost $J$, using the following formula: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}+Ïµ\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}+Ïµ\\right)), where\\ Ïµ=1e-5$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MjBT0eYQaY81"
      },
      "outputs": [],
      "source": [
        "def compute_BCE_cost(AL, Y):\n",
        "    \"\"\"\n",
        "    Implement the binary cross-entropy cost function using the above formula.\n",
        "\n",
        "    Arguments:\n",
        "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
        "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
        "\n",
        "    Returns:\n",
        "    cost -- binary cross-entropy cost\n",
        "    \"\"\"\n",
        "    \n",
        "    m = Y.shape[1]\n",
        "\n",
        "    # Compute loss from aL and y.\n",
        "    E = 1e-5\n",
        "    cost = -1/m * np.sum(np.multiply(np.log(AL+E), Y) + np.multiply((1-Y), np.log(1-AL+E)))\n",
        "    \n",
        "    cost = np.squeeze(cost)\n",
        "    assert(cost.shape == ())\n",
        "    \n",
        "    return cost"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aealRyKbcQzG"
      },
      "source": [
        "## 4.2. Categorical cross-entropy loss\n",
        "Compute the categorical cross-entropy cost $J$, using the following formula: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}+Ïµ\\right)), where\\ Ïµ = 1e-5$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Owx-kTdcfxV5"
      },
      "outputs": [],
      "source": [
        "def compute_CCE_cost(AL, Y):\n",
        "    \"\"\"\n",
        "    Implement the categorical cross-entropy cost function using the above formula.\n",
        "\n",
        "    Arguments:\n",
        "    AL -- probability vector corresponding to your label predictions, shape (number of classes, number of examples)\n",
        "    Y -- true \"label\" vector (one hot vector, for example: [[1], [0], [0]] represents rock, [[0], [1], [0]] represents paper, [[0], [0], [1]] represents scissors \n",
        "                              in a Rock-Paper-Scissors image classification), shape (number of classes, number of examples)\n",
        "\n",
        "    Returns:\n",
        "    cost -- categorical cross-entropy cost\n",
        "    \"\"\"\n",
        "    \n",
        "    m = Y.shape[1]\n",
        "\n",
        "    # Compute loss from aL and y.\n",
        "    E = 1e-5\n",
        "    cost = -1/m * np.sum(np.multiply(np.log(AL+E), Y))\n",
        "    \n",
        "    cost = np.squeeze(cost)\n",
        "    assert(cost.shape == ())\n",
        "    \n",
        "    return cost"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mpQah0JDdMyl"
      },
      "source": [
        "# Basic implementation (binary classification)\n",
        "\n",
        "Now we have all the tools we need to get started with classification. In this section, we will build a binary classifier using the functions we have previously written. We will create a model that can determine whether breast cancer is malignant or benign based on 30 features. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe the characteristics of the cell nuclei present in the image.\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "1.   radius (mean of distances from center to points on the perimeter)\n",
        "2.   texture (standard deviation of gray-scale values)\n",
        "3.   perimeter\n",
        "4.   area\n",
        "5.   smoothness (local variation in radius lengths)\n",
        "6.   compactness (perimeter^2 / area - 1.0)\n",
        "7.   concavity (severity of concave portions of the contour)\n",
        "8.   concave points (number of concave portions of the contour)\n",
        "9.   symmetry\n",
        "10.   fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three\n",
        "largest values) of these features were computed for each image,\n",
        "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
        "13 is Radius SE, field 23 is Worst Radius."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OzSS4zFHezi",
        "outputId": "2b1a47d0-3b3c-4bb5-f8da-a245cfe57f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of X: (30, 500)\n",
            "shape of y: (1, 500)\n",
            "shape of X_train: (30, 400) shape of y_train: (1, 400)\n",
            "shape of X_val: (30, 100) shape of y_val: (1, 100)\n"
          ]
        }
      ],
      "source": [
        "# load breast cancer wisconsin dataset\n",
        "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "X = X[:500].T\n",
        "y = np.expand_dims(y[:500], axis=1).T\n",
        "\n",
        "print(\"shape of X: \" + str(X.shape))\n",
        "print(\"shape of y: \" + str(y.shape))\n",
        "\n",
        "# min max scaling\n",
        "X = X.T\n",
        "min_X, max_X = X.min(axis = 0), X.max(axis = 0)\n",
        "X = (X - min_X) / (max_X - min_X)\n",
        "X = X.T\n",
        "\n",
        "# split training set and validation set\n",
        "X_train, y_train = X[:, :400], y[:, :400]\n",
        "X_val, y_val = X[:, 400:], y[:, 400:]\n",
        "\n",
        "print(\"shape of X_train: \" + str(X_train.shape) + \" shape of y_train: \" + str(y_train.shape))\n",
        "print(\"shape of X_val: \" + str(X_val.shape) + \" shape of y_val: \" + str(y_val.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "fI7JY5ESjhZ2",
        "outputId": "f43b97ef-7246-40f0-c229-f49f8ac9ce67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.720004\n",
            "Cost after iteration 100: 0.381173\n",
            "Cost after iteration 200: 0.228427\n",
            "Cost after iteration 300: 0.165228\n",
            "Cost after iteration 400: 0.134449\n",
            "Cost after iteration 500: 0.116508\n",
            "Cost after iteration 600: 0.104745\n",
            "Cost after iteration 700: 0.096440\n",
            "Cost after iteration 800: 0.090280\n",
            "Cost after iteration 900: 0.085535\n",
            "Cost after iteration 1000: 0.081750\n",
            "Cost after iteration 1100: 0.078658\n",
            "Cost after iteration 1200: 0.076084\n",
            "Cost after iteration 1300: 0.073887\n",
            "Cost after iteration 1400: 0.071980\n",
            "Cost after iteration 1500: 0.070300\n",
            "Cost after iteration 1600: 0.068798\n",
            "Cost after iteration 1700: 0.067438\n",
            "Cost after iteration 1800: 0.066195\n",
            "Cost after iteration 1900: 0.065048\n",
            "Cost after iteration 2000: 0.063989\n",
            "Cost after iteration 2100: 0.063007\n",
            "Cost after iteration 2200: 0.062091\n",
            "Cost after iteration 2300: 0.061228\n",
            "Cost after iteration 2400: 0.060413\n",
            "Cost after iteration 2500: 0.059642\n",
            "Cost after iteration 2600: 0.058909\n",
            "Cost after iteration 2700: 0.058213\n",
            "Cost after iteration 2800: 0.057548\n",
            "Cost after iteration 2900: 0.056911\n",
            "Cost after iteration 3000: 0.056301\n",
            "Cost after iteration 3100: 0.055714\n",
            "Cost after iteration 3200: 0.055148\n",
            "Cost after iteration 3300: 0.054601\n",
            "Cost after iteration 3400: 0.053920\n",
            "Cost after iteration 3500: 0.053300\n",
            "Cost after iteration 3600: 0.052721\n",
            "Cost after iteration 3700: 0.052168\n",
            "Cost after iteration 3800: 0.051642\n",
            "Cost after iteration 3900: 0.051135\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "layers_dims = [30, 15, 1]\n",
        "activation_fn = [\"relu\", \"sigmoid\"]\n",
        "learning_rate = 0.1\n",
        "num_iterations = 4000\n",
        "print_cost = True\n",
        "classes = 2\n",
        "costs = []  # keep track of cost\n",
        "model = Model(layers_dims, activation_fn)\n",
        "\n",
        "# Loop (batch gradient descent)\n",
        "for i in range(0, num_iterations):\n",
        "    # forward\n",
        "    AL = model.forward(X_train)\n",
        "\n",
        "    # compute cost\n",
        "    if classes == 2:\n",
        "        cost = compute_BCE_cost(AL, y_train)\n",
        "    else:\n",
        "        cost = compute_CCE_cost(AL, y_train)\n",
        "\n",
        "    # backward\n",
        "    dA_prev = model.backward(AL, y_train)\n",
        "    \n",
        "    # update\n",
        "    model.update(learning_rate)\n",
        "\n",
        "    if print_cost and i % 100 == 0:\n",
        "        print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        costs.append(cost)\n",
        "            \n",
        "# plot the cost\n",
        "plt.plot(np.squeeze(costs))\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('iterations (per hundreds)')\n",
        "plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "woCqucFUYXe6"
      },
      "outputs": [],
      "source": [
        "# Helper function\n",
        "def predict(X, y, model, classes):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of a  L-layer neural network.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data set of examples you would like to label\n",
        "    model -- trained model\n",
        "    classes - number of classes, 2 for binary classification, >2 for multi-class classification\n",
        "    \n",
        "    Returns:\n",
        "    p -- predictions for the given dataset X\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    n = len(model.linear) # number of layers in the neural network\n",
        "\n",
        "    if classes == 2:\n",
        "      p = np.zeros((1,m))\n",
        "    else:\n",
        "      p = np.zeros((classes, m))\n",
        "    \n",
        "    # Forward propagation\n",
        "    probas = model.forward(X)\n",
        "    \n",
        "    if classes == 2:\n",
        "      # convert probas to 0/1 predictions\n",
        "      for i in range(0, probas.shape[1]):\n",
        "          if probas[0,i] > 0.5:\n",
        "              p[0,i] = 1\n",
        "          else:\n",
        "              p[0,i] = 0\n",
        "\n",
        "      #print results\n",
        "      if y is not None:\n",
        "        print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
        "\n",
        "    else:\n",
        "      # convert probas to one hot vector predictions\n",
        "      prediction = np.argmax(probas, axis=0, out=None)\n",
        "    \n",
        "      for i in range(len(prediction)):\n",
        "          p[prediction[i], i] = 1\n",
        "\n",
        "      #print results\n",
        "      if y is not None:\n",
        "        correct = 0\n",
        "        for i in range(m):\n",
        "          if (p[:, i] == y[:, i]).all():\n",
        "            correct += 1\n",
        "        print(\"Accuracy: \"  + str(correct/m))\n",
        "        \n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkeoJrFZznMf",
        "outputId": "51cb34ef-d57e-4423-e111-7912fbd69a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9824999999999999\n"
          ]
        }
      ],
      "source": [
        "pred_train = predict(X_train, y_train, model, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mERo3g41zsyX",
        "outputId": "328fb270-040f-4028-a5a3-3739ac55049c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98\n"
          ]
        }
      ],
      "source": [
        "pred_val = predict(X_val, y_val, model, 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oMCpPFMVdj36"
      },
      "source": [
        "# Advanced implementation (multi class classification)\n",
        "\n",
        "In this section, we need to implement a multi-class classifier using the functions we have previously written. We will create a model that can classify ten handwritten digits. The MNIST handwritten digit classification problem is a standard dataset in computer vision and deep learning. We usually use convolutional deep-learning neural networks for image classification. However, using only dense layers appears to be enough to handle this simple dataset, and this is a good way to get started with image datasets. \n",
        "\n",
        "For data preprocessing, we need to change the data type into float and scale the values between 0 and 1.\n",
        "\n",
        "In Batch Gradient Descent, we consider all the samples for every step of Gradient Descent. But what if our dataset is huge? MNIST training data contains 60000 training samples, then to take one step, the model will have to calculate the gradients of all the 60000 samples. This does not seem an efficient way. Hence, mini-batch gradient descent is used in this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "bVSfqnXqXGdC",
        "outputId": "b22abfc5-dbaf-4800-ce46-16d084ceda38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of X_train: (784, 60000)\n",
            "shape of y_train: (10, 60000)\n",
            "shape of X_test: (784, 10000)\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "data = np.load(\"advanced_data.npz\")\n",
        "X_train = data[\"X_train\"]\n",
        "y_train = data[\"y_train\"].reshape(-1)\n",
        "X_test = data[\"X_test\"]\n",
        "\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
        "print('Test: X=%s' % (X_test.shape, ))\n",
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tplt.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tplt.imshow(X_train[i], cmap='gray', vmin=0, vmax=255)\n",
        "# show the figure\n",
        "plt.show()\n",
        "\n",
        "# Shuffle\n",
        "p = np.random.permutation(len(X_train))\n",
        "X_train = X_train[p]\n",
        "y_train = y_train[p]\n",
        "# Reshape\n",
        "X_train = X_train.reshape((X_train.shape[0], 28*28)).astype(\"float32\")\n",
        "X_train = X_train.T\n",
        "X_test = X_test.reshape((X_test.shape[0], 28*28)).astype(\"float32\")\n",
        "X_test = X_test.T\n",
        "m = y_train.shape[0]\n",
        "y_train = y_train.reshape((1, m))\n",
        "y_train = np.eye(10)[y_train.astype(\"int32\")]\n",
        "y_train = y_train.T.reshape(10, m)\n",
        "# Normalize\n",
        "X = X_train; y = y_train\n",
        "min_X, max_X = X.min(axis = 0), X.max(axis = 0)\n",
        "X_train = (X - min_X) / (max_X - min_X)\n",
        "min_y, max_y = y.min(axis = 0), y.max(axis = 0)\n",
        "y_train = (y - min_y) / (max_y - min_y)\n",
        "\n",
        "print(\"shape of X_train: \" + str(X_train.shape))\n",
        "print(\"shape of y_train: \" + str(y_train.shape))\n",
        "print(\"shape of X_test: \" + str(X_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAcf2tpQDR-",
        "outputId": "333e8ca6-3076-455c-fa49-af4e60bbe822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of X_train: (784, 48000) shape of y_train: (10, 48000)\n",
            "shape of X_val: (784, 12000) shape of y_val: (10, 12000)\n"
          ]
        }
      ],
      "source": [
        "# Split training and validation set.\n",
        "n = 48000\n",
        "X_val, y_val = X_train[:, n:], y_train[:, n:]\n",
        "X_train, y_train = X_train[:, :n], y_train[:, :n]\n",
        "\n",
        "print(\"shape of X_train: \" + str(X_train.shape) + \" shape of y_train: \" + str(y_train.shape))\n",
        "print(\"shape of X_val: \" + str(X_val.shape) + \" shape of y_val: \" + str(y_val.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HYD-qRs7doU0",
        "outputId": "511f784b-eee5-4d91-9f93-579f8e12863a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.175804\n",
            "Cost after iteration 10: 0.101276\n",
            "Cost after iteration 20: 0.083183\n",
            "Cost after iteration 30: 0.127157\n",
            "Cost after iteration 40: 0.055202\n",
            "Cost after iteration 50: 0.031729\n",
            "Cost after iteration 60: 0.011182\n",
            "Cost after iteration 70: 0.009532\n",
            "Cost after iteration 80: 0.024221\n",
            "Cost after iteration 90: 0.008751\n",
            "Cost after iteration 100: 0.020101\n",
            "Cost after iteration 110: 0.027052\n",
            "Cost after iteration 120: 0.013629\n",
            "Cost after iteration 130: 0.019076\n",
            "Cost after iteration 140: 0.012696\n",
            "Cost after iteration 150: 0.019204\n",
            "Cost after iteration 160: 0.058234\n",
            "Cost after iteration 170: 0.002368\n",
            "Cost after iteration 180: 0.009087\n",
            "Cost after iteration 190: 0.000683\n",
            "Cost after iteration 200: 0.006637\n",
            "Cost after iteration 210: 0.001222\n",
            "Cost after iteration 220: 0.002528\n",
            "Cost after iteration 230: 0.002051\n",
            "Cost after iteration 240: 0.003837\n",
            "Cost after iteration 250: 0.000454\n",
            "Cost after iteration 260: 0.007538\n",
            "Cost after iteration 270: 0.001906\n",
            "Cost after iteration 280: 0.000540\n",
            "Cost after iteration 290: 0.005096\n",
            "Cost after iteration 300: 0.001553\n",
            "Cost after iteration 310: 0.002482\n",
            "Cost after iteration 320: 0.000930\n",
            "Cost after iteration 330: 0.006623\n",
            "Cost after iteration 340: 0.004547\n",
            "Cost after iteration 350: 0.000548\n",
            "Cost after iteration 360: 0.000277\n",
            "Cost after iteration 370: 0.000053\n",
            "Cost after iteration 380: 0.001523\n",
            "Cost after iteration 390: 0.000557\n",
            "Cost after iteration 400: 0.000605\n",
            "Cost after iteration 410: 0.002081\n",
            "Cost after iteration 420: 0.000395\n",
            "Cost after iteration 430: 0.003503\n",
            "Cost after iteration 440: 0.001354\n",
            "Cost after iteration 450: 0.000577\n",
            "Cost after iteration 460: 0.001094\n",
            "Cost after iteration 470: 0.001314\n",
            "Cost after iteration 480: 0.002449\n",
            "Cost after iteration 490: 0.002228\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector, of shape (number of classes, number of examples)\n",
        "    mini_batch_size -- size of the mini-batches, integer\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]  # number of training examples\n",
        "    mini_batches = []\n",
        "        \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation]\n",
        "    \n",
        "    inc = mini_batch_size\n",
        "\n",
        "    # Step 2 - Partition (shuffled_X, shuffled_Y).\n",
        "    # Cases with a complete mini batch size only i.e each of 64 examples.\n",
        "    num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size:]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches\n",
        "\n",
        "\n",
        "layers_dims = [784, 256, 10]\n",
        "activation_fn = [\"relu\", \"softmax\"]\n",
        "learning_rate = 0.01\n",
        "num_iterations = 500\n",
        "batch_size = 32\n",
        "print_cost = True\n",
        "classes = 10\n",
        "costs = []  # keep track of cost\n",
        "model = Model(layers_dims, activation_fn)\n",
        "\n",
        "# Loop (gradient descent)\n",
        "for i in range(0, num_iterations):\n",
        "    mini_batches = random_mini_batches(X_train, y_train, batch_size)\n",
        "    for batch in mini_batches:\n",
        "        x_batch, y_batch = batch\n",
        "\n",
        "        # forward\n",
        "        AL = model.forward(x_batch)\n",
        "\n",
        "        # compute cost\n",
        "        if classes == 2:\n",
        "            cost = compute_BCE_cost(AL, y_batch)\n",
        "        else:\n",
        "            cost = compute_CCE_cost(AL, y_batch)\n",
        "\n",
        "        # backward\n",
        "        dA_prev = model.backward(AL, y_batch)\n",
        "        # update\n",
        "        model.update(learning_rate)\n",
        "\n",
        "    #if print_cost and i % 100 == 0:\n",
        "    if print_cost and i % 10 == 0:\n",
        "        print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        costs.append(cost)\n",
        "           \n",
        "# plot the cost\n",
        "plt.plot(np.squeeze(costs))\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('iterations (per tens)')\n",
        "plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI92fh4JXC1k",
        "outputId": "2f72751d-3582-415f-c0f1-cfb8c9bf5509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "pred_train = predict(X_train, y_train, model, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehjcfSU2XD3-",
        "outputId": "5cd33b4d-534a-4359-9014-1fdf60cde871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9779166666666667\n"
          ]
        }
      ],
      "source": [
        "pred_val = predict(X_val, y_val, model, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YHFDuq2BQ2qI"
      },
      "outputs": [],
      "source": [
        "pred_test = predict(X_test, None, model, 10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
